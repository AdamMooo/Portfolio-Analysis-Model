{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b967b0",
   "metadata": {},
   "source": [
    "# Portfolio Optimization Overview\n",
    "\n",
    "This portfolio model optimizes allocations across a selected basket of assets to maximize the Sharpe Ratio, leveraging both historical return data and forward-looking volatility estimates via GARCH. It also incorporates Monte Carlo simulations and GBM price forecasting to simulate risk and visualize outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "## Step-by-Step Breakdown\n",
    "\n",
    "### 1. Data Source and Preprocessing\n",
    "\n",
    "- Historical adjusted close prices are downloaded using Yahoo Finance.\n",
    "- Daily returns are calculated.\n",
    "- Returns are cleaned and annualized to estimate expected annual returns.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Volatility Forecasting with GARCH(1,1)\n",
    "\n",
    "Volatility is modeled using a GARCH(1,1) process to capture time-varying risk:\n",
    "\n",
    "- GARCH accounts for volatility clustering, a common property of financial time series.\n",
    "- Volatility estimates are annualized and used as inputs for both optimization and simulation.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Portfolio Risk and Return Calculations\n",
    "\n",
    "For each simulated portfolio, the script calculates:\n",
    "\n",
    "- Expected portfolio return\n",
    "- Total portfolio volatility\n",
    "- Sharpe ratio (risk-adjusted return)\n",
    "\n",
    "These values are derived using asset-level expected returns, variances, and covariances.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Monte Carlo Portfolio Optimization\n",
    "\n",
    "A large number of random portfolios are generated with different weight combinations.\n",
    "\n",
    "Each portfolio is evaluated based on:\n",
    "\n",
    "- Its expected return\n",
    "- Its risk (volatility)\n",
    "- Its Sharpe ratio\n",
    "\n",
    "The portfolio with the highest Sharpe ratio is selected as optimal.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. GBM-Based Price Path Simulation\n",
    "\n",
    "Geometric Brownian Motion (GBM) is used to simulate future asset prices based on:\n",
    "\n",
    "- The asset's expected return\n",
    "- The asset's volatility\n",
    "\n",
    "Thousands of price paths are generated for each asset. The model then extracts median paths and confidence intervals to visualize the expected behavior over time.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Excel Report Generation\n",
    "\n",
    "The script creates an Excel file that includes:\n",
    "\n",
    "- A portfolio summary with weights, expected returns, volatility, Sharpe ratios, and dollar allocation\n",
    "- A statistics sheet with total expected return and risk metrics\n",
    "- Charts for rolling volatility, efficient frontier, GBM forecasts, and real vs. simulated prices\n",
    "\n",
    "---\n",
    "\n",
    "## Model Strengths\n",
    "\n",
    "- Incorporates forward-looking volatility via GARCH\n",
    "- Monte Carlo simulation for robust optimization\n",
    "- GBM forecasting for scenario visualization\n",
    "- Structured Excel reporting with clean formatting\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations and Future Enhancements\n",
    "\n",
    "- Assumes return distributions are normal\n",
    "- Does not account for market crashes or jump risk\n",
    "- Excludes taxes, trading fees, and liquidity constraints\n",
    "- Lacks fundamental and macroeconomic signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04b2dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T15:40:23.962013Z",
     "start_time": "2025-06-02T15:40:17.143460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740bd410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T15:47:27.501840Z",
     "start_time": "2025-06-02T15:46:32.892882Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Portfolio Analysis Complete: 2025-06-02 | Invested: $25,000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "import os\n",
    "import datetime\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment, Font, PatternFill\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.drawing.image import Image as XLImage\n",
    "from arch import arch_model\n",
    "\n",
    "def bootstrap_price_paths(prices, returns, sim_days, sim_count, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    n = len(returns)\n",
    "    last_prices = prices.iloc[-1]\n",
    "    all_paths = {}\n",
    "    for ticker in prices.columns:\n",
    "        sampled_indices = np.random.randint(0, n, (sim_days, sim_count))\n",
    "        sampled_returns = returns[ticker].values[sampled_indices]\n",
    "        cum_returns = np.cumprod(1 + sampled_returns, axis=0)\n",
    "        all_paths[ticker] = last_prices[ticker] * cum_returns\n",
    "    return all_paths\n",
    "\n",
    "def bootstrap_portfolio_paths(returns, weights, sim_days, sim_count, S0, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    n = len(returns)\n",
    "    port_paths = np.zeros((sim_days + 1, sim_count))\n",
    "    port_paths[0] = S0\n",
    "    returns_array = returns.values\n",
    "    for i in range(sim_count):\n",
    "        idx = np.random.randint(0, n, sim_days)\n",
    "        sample = returns_array[idx, :]\n",
    "        port_rets = sample.dot(weights)\n",
    "        cum_rets = np.cumprod(1 + port_rets)\n",
    "        port_paths[1:, i] = S0 * cum_rets\n",
    "    return port_paths\n",
    "\n",
    "def auto_adjust_column_width(ws):\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        column = col[0].column_letter\n",
    "        for cell in col:\n",
    "            if cell.value:\n",
    "                length = len(str(cell.value))\n",
    "                if length > max_length:\n",
    "                    max_length = length\n",
    "        ws.column_dimensions[column].width = max_length + 2\n",
    "\n",
    "# Settings\n",
    "tickers = ['BNS', 'BTCC-B.TO', 'VOO', 'TSM', 'GOOG']\n",
    "investment_amount = 25000\n",
    "start_date = (datetime.date.today() - pd.Timedelta(days=365*3)).strftime('%Y-%m-%d')\n",
    "end_date = datetime.date.today().strftime('%Y-%m-%d')\n",
    "risk_free_rate = 0.0495\n",
    "output_file = 'Portfolio Analysis.xlsx'\n",
    "\n",
    "# 1. Data\n",
    "prices = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# 2. Volatility & Returns\n",
    "garch_volatility = {}\n",
    "for ticker in tickers:\n",
    "    r_pct = returns[ticker] * 100\n",
    "    model = arch_model(r_pct, vol='Garch', p=1, q=1)\n",
    "    res = model.fit(disp='off')\n",
    "    forecast = res.forecast(horizon=1)\n",
    "    daily_vol = np.sqrt(forecast.variance.values[-1, 0])\n",
    "    garch_volatility[ticker] = daily_vol * np.sqrt(252) / 100\n",
    "\n",
    "mean_daily_returns = returns.mean()\n",
    "expected_annual_returns = mean_daily_returns * 252\n",
    "cov_matrix = returns.cov() * 252\n",
    "rolling_volatility = returns.rolling(window=21).std() * np.sqrt(252)\n",
    "individual_sharpes = (expected_annual_returns - risk_free_rate) / np.sqrt(np.diag(cov_matrix))\n",
    "\n",
    "# 3. Portfolio Optimization\n",
    "n_portfolios = 100000\n",
    "results = np.zeros((n_portfolios, 4))\n",
    "weights_record = []\n",
    "min_weight = 0.05\n",
    "max_weight = 0.60\n",
    "\n",
    "for _ in range(n_portfolios):\n",
    "    w = np.random.random(len(tickers))\n",
    "    w /= w.sum()\n",
    "    if np.any(w > max_weight) or np.any(w < min_weight):\n",
    "        continue\n",
    "    port_return = w.dot(expected_annual_returns)\n",
    "    port_vol = np.sqrt(w.T @ cov_matrix @ w)\n",
    "    sharpe_ratio = (port_return - risk_free_rate) / port_vol\n",
    "    indiv_risks = w * np.sqrt(np.diag(cov_matrix))\n",
    "    div_ratio = indiv_risks.sum() / port_vol if port_vol != 0 else 0\n",
    "    idx = len(weights_record)\n",
    "    results[idx] = [port_return, port_vol, sharpe_ratio, div_ratio]\n",
    "    weights_record.append(w)\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    results[:len(weights_record)],\n",
    "    columns=['Return', 'Volatility', 'Sharpe', 'DivRatio']\n",
    ")\n",
    "max_sharpe_idx = results_df['Sharpe'].idxmax()\n",
    "opt_weights = weights_record[max_sharpe_idx]\n",
    "max_div_idx = results_df['DivRatio'].idxmax()\n",
    "opt_weights_div = weights_record[max_div_idx]\n",
    "\n",
    "equal_weights = np.ones(len(tickers)) / len(tickers)\n",
    "bench_return = equal_weights.dot(expected_annual_returns)\n",
    "bench_vol = np.sqrt(equal_weights.T @ cov_matrix @ equal_weights)\n",
    "bench_sharpe = (bench_return - risk_free_rate) / bench_vol\n",
    "benchmark_stats = {\n",
    "    'Equal-Weight Return': [bench_return],\n",
    "    'Equal-Weight Volatility': [bench_vol],\n",
    "    'Equal-Weight Sharpe': [bench_sharpe]\n",
    "}\n",
    "\n",
    "# 4. Summary DataFrames\n",
    "def make_portfolio_df(weights):\n",
    "    return pd.DataFrame({\n",
    "        'Ticker': tickers,\n",
    "        'Weight': np.round(weights, 4),\n",
    "        'Expected Return %': np.round(expected_annual_returns.values * 100, 2),\n",
    "        'Volatility': np.round(np.sqrt(np.diag(cov_matrix)), 4),\n",
    "        'Sharpe Ratio': np.round(individual_sharpes.values, 2),\n",
    "        'Investment ($)': np.round(weights * investment_amount, 2),\n",
    "        'Expected Return ($)': np.round(expected_annual_returns.values * investment_amount * weights, 2)\n",
    "    }).sort_values(by='Weight', ascending=False)\n",
    "\n",
    "opt_df = make_portfolio_df(opt_weights)\n",
    "opt_df_div = make_portfolio_df(opt_weights_div)\n",
    "\n",
    "# 5. GBM Simulation\n",
    "sim_days = 252 * 2\n",
    "sim_count = 100000\n",
    "dt = 1 / 252\n",
    "gbm_expected_returns = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    S0 = prices[ticker].iloc[-1]\n",
    "    mu = expected_annual_returns[ticker]\n",
    "    sigma = np.sqrt(cov_matrix.loc[ticker, ticker])\n",
    "    np.random.seed(42)\n",
    "    price_paths = np.zeros((sim_days, sim_count))\n",
    "    price_paths[0] = S0\n",
    "    for t in range(1, sim_days):\n",
    "        z = np.random.standard_normal(sim_count)\n",
    "        price_paths[t] = price_paths[t-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * z)\n",
    "    end_prices = price_paths[-1]\n",
    "    gbm_returns = (end_prices / S0) ** (1 / 3) - 1\n",
    "    gbm_expected_returns.append(np.round(np.mean(gbm_returns) * 100, 2))\n",
    "\n",
    "opt_df['GBM Expected Return %'] = gbm_expected_returns\n",
    "\n",
    "# 6. Bootstrap Simulation\n",
    "boot_sim_count = 10000\n",
    "boot_paths = bootstrap_price_paths(prices, returns, sim_days, boot_sim_count)\n",
    "boot_port_paths = bootstrap_portfolio_paths(returns, opt_weights, sim_days, boot_sim_count, investment_amount)\n",
    "\n",
    "boot_cagr = []\n",
    "for ticker in tickers:\n",
    "    final_prices = boot_paths[ticker][-1]\n",
    "    S0 = prices[ticker].iloc[-1]\n",
    "    cagr = (final_prices / S0) ** (1 / 2) - 1\n",
    "    boot_cagr.append(np.mean(cagr) * 100)\n",
    "opt_df['Bootstrapped CAGR %'] = np.round(boot_cagr, 2)\n",
    "\n",
    "boot_port_final = boot_port_paths[-1]\n",
    "port_boot_stats_df = pd.DataFrame({\n",
    "    \"5th Percentile\": [np.percentile(boot_port_final, 5)],\n",
    "    \"Median\": [np.median(boot_port_final)],\n",
    "    \"95th Percentile\": [np.percentile(boot_port_final, 95)],\n",
    "    \"Mean\": [np.mean(boot_port_final)]\n",
    "})\n",
    "\n",
    "# 7. Plots\n",
    "bootstrapped_charts = []\n",
    "for ticker in tickers:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(boot_paths[ticker][:, :100], alpha=0.2)\n",
    "    median_path = np.median(boot_paths[ticker], axis=1)\n",
    "    plt.plot(median_path, color=\"black\", linewidth=2)\n",
    "    mean_path = np.mean(boot_paths[ticker], axis=1)\n",
    "    plt.plot(mean_path, linestyle=\"--\", linewidth=2)\n",
    "    plt.title(f\"{ticker} Bootstrap Paths\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.tight_layout()\n",
    "    img = f\"{ticker}_bootstrap.png\"\n",
    "    plt.savefig(img)\n",
    "    plt.close()\n",
    "    bootstrapped_charts.append((ticker, img))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(boot_port_paths[:, :100], alpha=0.2)\n",
    "median = np.median(boot_port_paths, axis=1)\n",
    "plt.plot(median, color=\"black\", linewidth=2)\n",
    "mean = np.mean(boot_port_paths, axis=1)\n",
    "plt.plot(mean, linestyle=\"--\", linewidth=2)\n",
    "plt.title(\"Portfolio Bootstrap Paths\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.tight_layout()\n",
    "port_boot_img = \"portfolio_bootstrap.png\"\n",
    "plt.savefig(port_boot_img)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for t in tickers:\n",
    "    plt.plot(rolling_volatility[t], label=t)\n",
    "plt.title(\"21-Day Rolling Volatility (Annualized)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "vol_plot = \"rolling_volatility.png\"\n",
    "plt.savefig(vol_plot)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(results_df['Volatility'], results_df['Return'], c=results_df['Sharpe'], cmap='viridis', alpha=0.6)\n",
    "opt_point = results_df.loc[max_sharpe_idx]\n",
    "plt.scatter(opt_point['Volatility'], opt_point['Return'], c='red', marker='*', s=200)\n",
    "plt.title(\"Efficient Frontier\")\n",
    "plt.xlabel(\"Volatility\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.tight_layout()\n",
    "frontier_plot = \"efficient_frontier.png\"\n",
    "plt.savefig(frontier_plot)\n",
    "plt.close()\n",
    "\n",
    "simulated_charts = []\n",
    "for ticker in tickers:\n",
    "    S0 = prices[ticker].iloc[-1]\n",
    "    mu = expected_annual_returns[ticker]\n",
    "    sigma = np.sqrt(cov_matrix.loc[ticker, ticker])\n",
    "    np.random.seed(42)\n",
    "    paths = np.zeros((sim_days, sim_count))\n",
    "    paths[0] = S0\n",
    "    for t in range(1, sim_days):\n",
    "        z = np.random.standard_normal(sim_count)\n",
    "        paths[t] = paths[t-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * z)\n",
    "    percentiles = np.percentile(paths, [10, 50, 90], axis=1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(percentiles[1], label=\"Median\")\n",
    "    plt.fill_between(range(sim_days), percentiles[0], percentiles[2], alpha=0.2)\n",
    "    plt.title(f\"{ticker} GBM Paths\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.tight_layout()\n",
    "    img = f\"{ticker}_gbm.png\"\n",
    "    plt.savefig(img)\n",
    "    plt.close()\n",
    "    simulated_charts.append((ticker, img))\n",
    "\n",
    "# 8. Comparison Table\n",
    "historical_cagr = []\n",
    "n_days = (prices.index[-1] - prices.index[0]).days\n",
    "years = n_days / 365.25\n",
    "total_return = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    S0 = prices[ticker].iloc[0]\n",
    "    S1 = prices[ticker].iloc[-1]\n",
    "    cagr = (S1 / S0) ** (1 / years) - 1\n",
    "    historical_cagr.append(cagr * 100)\n",
    "    total_return.append((S1 / S0 - 1) * 100)\n",
    "\n",
    "compare_df = pd.DataFrame({\n",
    "    'Ticker': tickers,\n",
    "    'Weight in Opt Portf': np.round(opt_weights, 4),\n",
    "    'Exp. Return % (Mean)': np.round(expected_annual_returns.values * 100, 2),\n",
    "    'Hist. CAGR %': np.round(historical_cagr, 2),\n",
    "    'Bootstrapped CAGR %': np.round(opt_df['Bootstrapped CAGR %'].values, 2),\n",
    "    'GBM Exp. Return %': np.round(opt_df['GBM Expected Return %'].values, 2),\n",
    "    'Ann. Volatility %': np.round(np.sqrt(np.diag(cov_matrix)) * 100, 2),\n",
    "    'Sharpe Ratio': np.round(individual_sharpes.values, 2),\n",
    "    'Total Return %': np.round(total_return, 2)\n",
    "})\n",
    "\n",
    "# 9. Export to Excel\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    opt_df.to_excel(writer, sheet_name='Portfolio Summary', index=False)\n",
    "    opt_df_div.to_excel(writer, sheet_name='Max Diversification', index=False)\n",
    "    compare_df.to_excel(writer, sheet_name='Comparison Table', index=False)\n",
    "\n",
    "    sheet = writer.sheets['Portfolio Summary']\n",
    "    sheet.insert_image(\"L2\", vol_plot)\n",
    "    sheet.insert_image(\"L32\", frontier_plot)\n",
    "\n",
    "    summary = {\n",
    "        'Investment Amount ($)': [investment_amount],\n",
    "        'Portfolio Exp Return %': [opt_weights.dot(expected_annual_returns) * 100],\n",
    "        'Portfolio Exp Return ($)': [opt_weights.dot(expected_annual_returns) * investment_amount],\n",
    "        'Portfolio Volatility': [np.sqrt(opt_weights.T @ cov_matrix @ opt_weights)],\n",
    "        'Max Sharpe Ratio': [opt_point['Sharpe']]\n",
    "    }\n",
    "    pd.DataFrame(summary).to_excel(writer, sheet_name='Stats', index=False)\n",
    "    pd.DataFrame(benchmark_stats).to_excel(writer, sheet_name='Stats', startrow=8, index=False)\n",
    "\n",
    "    boot_cagr_df = pd.DataFrame({\n",
    "        \"Ticker\": tickers,\n",
    "        \"Bootstrapped 2Y CAGR %\": np.round(boot_cagr, 2)\n",
    "    })\n",
    "    boot_cagr_df.to_excel(writer, sheet_name='Bootstrapped CAGRs', index=False)\n",
    "    port_boot_stats_df.to_excel(writer, sheet_name='Portfolio Boot Results', index=False)\n",
    "\n",
    "    path_sheet = writer.book.add_worksheet('Price Paths')\n",
    "    row_offset = 1\n",
    "    for _, img in simulated_charts:\n",
    "        path_sheet.insert_image(row_offset, 1, img)\n",
    "        row_offset += 30\n",
    "\n",
    "    boot_path_sheet = writer.book.add_worksheet('Boot Paths')\n",
    "    row_offset = 1\n",
    "    for _, img in bootstrapped_charts:\n",
    "        boot_path_sheet.insert_image(row_offset, 1, img)\n",
    "        row_offset += 30\n",
    "    for _, img in [(t, img) for t, img in bootstrapped_charts]:\n",
    "        boot_path_sheet.insert_image(row_offset, 1, img)\n",
    "        row_offset += 30\n",
    "    boot_path_sheet.insert_image(row_offset, 1, port_boot_img)\n",
    "    row_offset += 30\n",
    "\n",
    "# 10. Formatting\n",
    "wb = load_workbook(output_file)\n",
    "for name in wb.sheetnames:\n",
    "    ws = wb[name]\n",
    "    auto_adjust_column_width(ws)\n",
    "\n",
    "ws = wb['Portfolio Summary']\n",
    "font = Font(name='Calibri', size=11)\n",
    "alignment = Alignment(horizontal='center', vertical='center')\n",
    "fill = PatternFill(start_color='E0E0E0', end_color='E0E0E0', fill_type='solid')\n",
    "for cell in ws[1]:\n",
    "    cell.font = Font(bold=True, name='Calibri', size=11)\n",
    "    cell.alignment = alignment\n",
    "    cell.fill = fill\n",
    "for row in ws.iter_rows(min_row=2, max_row=ws.max_row, max_col=ws.max_column):\n",
    "    for idx, cell in enumerate(row, start=1):\n",
    "        cell.font = font\n",
    "        cell.alignment = alignment\n",
    "        if ws.cell(row=1, column=idx).value == 'Weight':\n",
    "            cell.number_format = '0.00%'\n",
    "ws.freeze_panes = 'A2'\n",
    "\n",
    "if 'Stats' in wb.sheetnames:\n",
    "    ws_stats = wb['Stats']\n",
    "    for cell in ws_stats[1]:\n",
    "        cell.font = Font(bold=True, name='Calibri', size=11)\n",
    "        cell.alignment = alignment\n",
    "        cell.fill = fill\n",
    "    for row in ws_stats.iter_rows(min_row=2, max_row=ws_stats.max_row, max_col=ws_stats.max_column):\n",
    "        for cell in row:\n",
    "            cell.font = font\n",
    "            cell.alignment = alignment\n",
    "    ws_stats.freeze_panes = 'A2'\n",
    "\n",
    "wb.save(output_file)\n",
    "\n",
    "# 11. Cleanup\n",
    "cleanup = [vol_plot, frontier_plot, port_boot_img] + \\\n",
    "          [img for _, img in simulated_charts] + \\\n",
    "          [img for _, img in bootstrapped_charts]\n",
    "for img in cleanup:\n",
    "    if os.path.exists(img):\n",
    "        os.remove(img)\n",
    "\n",
    "print(f\"\\nPortfolio Analysis Complete: {end_date} | Invested: ${investment_amount:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b3f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
